{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "import re\n",
    "import numpy\n",
    "import random\n",
    "from random import shuffle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from create_model_fittest import build_network\n",
    "\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "maximum_sense = 5\n",
    "project_path = \"/root/shared_folder/inputs/\" # \"/home/ali/projects/deep_wsd/inputs/\"\n",
    "\n",
    "def pad_truncate(terms_sequence):\n",
    "    terms = terms_sequence.split()\n",
    "    if len(terms) > window_size:\n",
    "        terms = terms[0:window_size]\n",
    "    else:\n",
    "        for i in range(window_size - len(terms)):\n",
    "            terms.append('T0')\n",
    "    terms = \" \".join(terms)\n",
    "    return terms\n",
    "\n",
    "concept_dic = {}\n",
    "for file in os.listdir(project_path + \"/contexts/\"):\n",
    "\n",
    "    if file.endswith(\".txt\") and file.startswith(\"_\") is False:\n",
    "        concept = file.split(\"_\")[2]\n",
    "        concept_dic[concept] = {}\n",
    "        file_reader = open(project_path + \"/contexts/\" + file, \"r\")\n",
    "        for instance in file_reader:\n",
    "            instance = instance.rstrip()\n",
    "            left, right = instance.replace(\" RIGHT: \", \"RIGHT:\").split(\"RIGHT:\")\n",
    "            instance_no, left = left.replace(\"LEFT: \", \"LEFT:\").split(\"LEFT:\")\n",
    "            instance_no = instance_no.replace(\" >> \", \"\")\n",
    "            left = pad_truncate(left)\n",
    "            right = pad_truncate(right)\n",
    "            concept_dic[concept][instance_no] = [left, right]\n",
    "        file_reader.close()\n",
    "\n",
    "amb_term_dic = {}\n",
    "file_reader = open(project_path + \"ambiguous_terms.txt\", \"r\")\n",
    "for line in file_reader:\n",
    "    elements = line.split(\") \")[1].split(\"\\t<<\")[0].split(\"\\t\")\n",
    "    amb_term_dic[elements[0]] = elements[1:]\n",
    "file_reader.close()\n",
    "\n",
    "amb_term_instance_dic = {}\n",
    "for file in sorted(os.listdir(project_path + \"/plain/\")):\n",
    "\n",
    "    concept = file.split(\"_\")[0]\n",
    "    amb_term_instance_dic[concept] = {}\n",
    "\n",
    "    file_reader = open(project_path + \"/plain/\" + file, \"r\")\n",
    "    for amb_instance in file_reader:\n",
    "        head = re.search(\"<head.*</head>\", amb_instance).group(0)\n",
    "        instance_no = re.search('instance=\".*?\"', head).group(0)\n",
    "        instance_no = instance_no.split('\"')[1]\n",
    "        sense = re.search('sense=\".*?\"', head).group(0).split('\"')[1]\n",
    "        candidates = re.search('candidates=\".*?\"', head).group(0).split('\"')[1].split(\",\")\n",
    "\n",
    "        amb_term_instance_dic[concept][instance_no] = []\n",
    "\n",
    "        for candidate_concept in amb_term_dic[concept]:\n",
    "            attr_list = concept_dic[concept][instance_no] + [candidate_concept]\n",
    "            if candidate_concept == sense:\n",
    "                amb_term_instance_dic[concept][instance_no].append(attr_list + [1.0])\n",
    "            else:\n",
    "                amb_term_instance_dic[concept][instance_no].append(attr_list + [0.0])\n",
    "    file_reader.close()\n",
    "\n",
    "'''\n",
    "file_writer = open(\"text.txt\", \"w\")\n",
    "for amb_term, instance_no in amb_term_instance_dic.items():\n",
    "    for key, values in instance_no.items():\n",
    "        for value in values:\n",
    "            file_writer.write(str(amb_term) + \" \" + str(key) + \" \" + str(value[0:5]) + \"\\n\")\n",
    "            print(str(amb_term) + \" \" + str(key) + \" \" + str(value))\n",
    "file_writer.close()\n",
    "'''\n",
    "\n",
    "terms_concepts_dic = {}\n",
    "file_reader = open(project_path + \"/contexts/_terms_CUIs.txt\", \"r\")\n",
    "for line in file_reader:\n",
    "    term, concepts = line.rstrip().split(\": \")\n",
    "    concepts_str = \"\"\n",
    "    for i in range(maximum_sense - (len(concepts.split()))):\n",
    "        concepts_str += \" C0000000\"\n",
    "    concepts_str = concepts + concepts_str\n",
    "    terms_concepts_dic[term] = concepts_str\n",
    "file_reader.close()\n",
    "print(len(terms_concepts_dic))\n",
    "\n",
    "expanded_instances = []\n",
    "# true_labels = []\n",
    "for amb_term, instances in amb_term_instance_dic.items():\n",
    "    for instance_key, inner_instances in instances.items():\n",
    "        for value in inner_instances:\n",
    "            # print(str(amb_term) + \" \" + str(instance_key) + \" \" + str(value))\n",
    "            left_right_terms = value[0].split(\" \") + value[1].split(\" \")\n",
    "            concepts = \"\"\n",
    "            for term in left_right_terms:\n",
    "                concepts += terms_concepts_dic[term] + \" \"\n",
    "            concepts += value[2] + \" C0000000\" * 4\n",
    "            # print(concepts)\n",
    "            expanded_instances.append(concepts)\n",
    "            # true_labels.append(value[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for amb_term, instances in concept_dic.items():\n",
    "    print amb_term\n",
    "    for instance, values in instances.items():\n",
    "        print instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for training with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=False, num_words=0)\n",
    "tokenizer.fit_on_texts(expanded_instances)\n",
    "sequences = tokenizer.texts_to_sequences(expanded_instances)\n",
    "\n",
    "print(len(sequences))\n",
    "print(\"HI\")\n",
    "concept_dic = tokenizer.word_index\n",
    "\n",
    "MOST_FREQUENT_LEVEL = 10\n",
    "print('Top', MOST_FREQUENT_LEVEL, 'Most Frequent Concepts' + \":\")\n",
    "for concept_id, index in sorted(concept_dic.items(), key=operator.itemgetter(1))[:MOST_FREQUENT_LEVEL]:\n",
    "    print('  >>>', concept_id, '   ', index)\n",
    "\n",
    "\"\"\"Chunking the data\"\"\"\n",
    "for i in range(0, len(sequences)):\n",
    "    chunks = [sequences[i][x:x + maximum_sense] for x in range(0, len(sequences[i]), maximum_sense)]\n",
    "    sequences[i] = []\n",
    "    for element in chunks:\n",
    "        sequences[i].append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swap_axes(sequences):\n",
    "    \"\"\"\n",
    "    We swap axes to a have proper input for Keras, \n",
    "    and also typecast the whole data as a list and each entry (i.e. input column) as numpy-array.\n",
    "    \"\"\"\n",
    "    sequences_T = list(numpy.swapaxes(sequences, 0, 1))\n",
    "    for i in range(0, len(sequences_T)):\n",
    "        sequences_T[i] = numpy.asarray(sequences_T[i])\n",
    "        \n",
    "    return sequences_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_provider(dataset_dic):\n",
    "    \"\"\"\n",
    "    We swap axes to a have proper input for Keras, \n",
    "    and also typecast the whole data as a list and each entry (i.e. input column) as numpy-array.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for amb_term, instances_no in dataset_dic.items():\n",
    "        for instance_no, instance in instances_no.items():\n",
    "            for inner_instance in instance:\n",
    "                X.append(inner_instance[0][:])\n",
    "                y.append(inner_instance[-1])\n",
    "    # print(numpy.asarray(X).shape, len(y))\n",
    "    X = swap_axes(X)\n",
    "    return X, numpy.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sequence_dic = {}\n",
    "amb_term_instance_list_dic = {}\n",
    "sequence_counter = 0\n",
    "for amb_term, instances in amb_term_instance_dic.items():\n",
    "    data_sequence_dic[amb_term] = {}\n",
    "    amb_term_instance_list_dic[amb_term] = []\n",
    "    for instance_key, inner_instances in instances.items():\n",
    "        amb_term_instance_list_dic[amb_term].append(instance_key)\n",
    "        data_sequence_dic[amb_term][instance_key] = []\n",
    "        for value in inner_instances:\n",
    "            data_sequence_dic[amb_term][instance_key].append([sequences[sequence_counter], value[-1]])\n",
    "            sequence_counter += 1\n",
    "\n",
    "training_set_dic = {}\n",
    "test_set_dic = {}\n",
    "validation_set_dic = {}\n",
    "\n",
    "for amb_term, instances_no in amb_term_instance_list_dic.items():\n",
    "    random = list(range(0, len(instances_no)))\n",
    "    shuffle(random)\n",
    "    \n",
    "    test_indices = random[0:int(0.1 * len(random))]\n",
    "    test_instances = numpy.asarray(instances_no)[test_indices]\n",
    "    test_set_dic[amb_term] = {}\n",
    "    for instance in test_instances:\n",
    "        test_set_dic[amb_term][instance] = data_sequence_dic[amb_term][instance]\n",
    "        \n",
    "    validation_indices = random[len(test_indices):int(0.15 * len(random))]\n",
    "    validation_instances = numpy.asarray(instances_no)[validation_indices]\n",
    "    validation_set_dic[amb_term] = {}\n",
    "    for instance in validation_instances:\n",
    "        validation_set_dic[amb_term][instance] = data_sequence_dic[amb_term][instance]\n",
    "        \n",
    "    training_indices = random[len(test_indices) + len(validation_indices):]\n",
    "    training_instances = numpy.asarray(instances_no)[training_indices]\n",
    "    training_set_dic[amb_term] = {}\n",
    "    for instance in training_instances:\n",
    "        training_set_dic[amb_term][instance] = data_sequence_dic[amb_term][instance]\n",
    "\n",
    "training_X, training_y = data_provider(training_set_dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_set_confusion_matrices(set_dic, amb_term_dic):\n",
    "    confusion_matrices_dic = {}\n",
    "    for amb_term, instance_no in set_dic.items():\n",
    "        dim = len(amb_term_dic[amb_term])\n",
    "        confusion_matrix = []\n",
    "        for i in range(dim):\n",
    "            confusion_matrix.append([])\n",
    "            for j in range(dim):\n",
    "                confusion_matrix[i].append(0)\n",
    "        # print(numpy.asarray(confusion_matrix).shape)\n",
    "        confusion_matrices_dic[amb_term] = confusion_matrix\n",
    "    return confusion_matrices_dic\n",
    "\n",
    "def print_confusion_matrix(matrix):\n",
    "    for i in range(len(matrix[0])):\n",
    "        for j in range(len(matrix[0])):\n",
    "            print matrix[i][j], \" \",\n",
    "        print \n",
    "    \n",
    "def print_confusion_matrices(confusion_matrices_dic):\n",
    "    for term, matrix in sorted(confusion_matrices_dic.items()):\n",
    "        print(term)\n",
    "        print(\"===\")\n",
    "        print_confusion_matrix(matrix)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(matrix):\n",
    "    count_total = 0\n",
    "    count_diagonal = 0\n",
    "    for i in range(len(matrix[0])):\n",
    "        count_diagonal += matrix[i][i]\n",
    "        for j in range(len(matrix[0])):\n",
    "            count_total += matrix[i][j]\n",
    "    accuracy = float(count_diagonal) / count_total\n",
    "    return accuracy\n",
    "\n",
    "def cal_set_accuracies(set_confusion_matrices_dic):\n",
    "    all_accuracies = []\n",
    "    for amb_term, matrix in set_confusion_matrices_dic.items():\n",
    "        all_accuracies.append(cal_accuracy(matrix))\n",
    "    final_accuracy = sum(all_accuracies) / len(all_accuracies)\n",
    "    return final_accuracy\n",
    "\n",
    "def cal_set_accuracy(set_dic, confusion_metrices_dic, set_predictions, label):\n",
    "    i = 0\n",
    "    for amb_term, instances_no in set_dic.items():\n",
    "        for instance_no, instances in instances_no.items():\n",
    "            # print(instance_no)\n",
    "            true_labels = []\n",
    "            predicted_labels = []\n",
    "            for instance in instances:\n",
    "                true_labels.append(instance[-1])\n",
    "                predicted_labels.append(float(set_predictions[i]))\n",
    "                i += 1\n",
    "            argmax_true_labels = numpy.array(true_labels).argmax()\n",
    "            argmax_predicated_labels = numpy.array(predicted_labels).argmax()\n",
    "            confusion_metrices_dic[amb_term][argmax_true_labels][argmax_predicated_labels] += 1\n",
    "        # break\n",
    "        \n",
    "    average_accuracies = \"%.2f\" % (cal_set_accuracies(confusion_metrices_dic) * 100)\n",
    "    \n",
    "    print(label + \" \" + \"accuracy: \" + average_accuracies + \"%\")\n",
    "    \n",
    "    return (average_accuracies)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epocs = 1000\n",
    "embedding_file = project_path + \"embeddings/WSD_Embeddings_50D_0_7.emb\"\n",
    "model, embedding_layers = build_network(concept_dic=concept_dic, embeddings_file=embedding_file,\n",
    "                                        MAX_SENSE_LENGTH=maximum_sense, CONTEXT_WINDOW_SIZE=window_size,\n",
    "                                        PRE_TRAINED=True,\n",
    "                                        UPDATABLE=True,\n",
    "                                        optimizer='rmsprop',\n",
    "                                        output_activation=\"linear\",\n",
    "                                        EMBEDDING_DIM=50,\n",
    "                                        dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = 0\n",
    "bests_validation_accuracy = 0\n",
    "\n",
    "for epoc in range(num_epocs):\n",
    "\n",
    "    print \"\\nEpoch\", str(epoc + 1) + \"/\" + str(num_epocs)\n",
    "    history = model.fit(training_X, training_y, batch_size=128, epochs=1)\n",
    "\n",
    "    validation_X, validation_y = data_provider(validation_set_dic)\n",
    "    training_pred = model.predict(training_X)\n",
    "    validation_pred = model.predict(validation_X)\n",
    "\n",
    "    training_confusion_matrices_dic = create_set_confusion_matrices(training_set_dic, amb_term_dic)\n",
    "    validation_confusion_matrices_dic = create_set_confusion_matrices(validation_set_dic, amb_term_dic)\n",
    "    test_confusion_matrices_dic = create_set_confusion_matrices(test_set_dic, amb_term_dic)\n",
    "\n",
    "    training_epoch_accuracy = cal_set_accuracy(training_set_dic, training_confusion_matrices_dic, training_pred, \"Training\")\n",
    "    validation_epoch_accuracy = cal_set_accuracy(validation_set_dic, validation_confusion_matrices_dic, validation_pred, \"Validation\")\n",
    "    \n",
    "    if validation_epoch_accuracy > bests_validation_accuracy:\n",
    "        bests_validation_accuracy = validation_epoch_accuracy\n",
    "        best_epoch = epoc + 1\n",
    "        \n",
    "    print \"Maximum validation accuracy is\", bests_validation_accuracy, \"observed in epoch\",  best_epoch, \".\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for amb_term, instances_no in sorted(validation_confusion_matrices_dic.items()):\n",
    "    print amb_term\n",
    "    print \"-------\"\n",
    "    print_confusion_matrix(validation_confusion_matrices_dic[amb_term])\n",
    "    print \"-------\"\n",
    "    print \"accuracy:\", \"%.2f\" % (cal_accuracy(validation_confusion_matrices_dic[amb_term]) * 100) + \"%\" \n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
